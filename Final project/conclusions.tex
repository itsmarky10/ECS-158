\section{Conclusion}
As we see in the time trials, SNOW performed the best in each case. When we work with a million $x$ values, it proves to be the very best. OpenMP and CUDA were neck to neck and the serial version was the slowest, as expected. Possibly due to the optimization in R's vectorization style as a programming language, computations were done faster than its C++ counterparts. Unless these C++ interfaces get optimized further, in practice we would want to stick to using R for the parallelization of this problem.
\\ \\
Nonetheless, we definitely achieved the speed up we were looking for: all parallel algorithms did much better than the serial version while maintaining the accuracy. However, we could have done better yet! In our testing, the length $n$ was much greater than the number of columns in the final basis matrix. Since each element in the matrix can technically be found independently of the other elements, we could have done the parallelization over the rows instead of the columns - or whichever is the largest of the two in practice. This would make it so there is less to do for each parallelization but there are more tasks to accomplish as opposed to its current style which would make it so some of the workers remain inactive since there are such few tasks.
